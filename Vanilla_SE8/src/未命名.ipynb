{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REUTERS_SOURCE_DIR = '../corpus/reuters21578/'\n",
    "REUTERS_CORPUS_OUTPUT = '../corpus/reuters_corpus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reuters_corpus():\n",
    "\n",
    "    target_files = [f for f in os.listdir(REUTERS_SOURCE_DIR) if f.endswith('.sgm')]\n",
    "    target_files = sorted(target_files)\n",
    "\n",
    "    # Extract information\n",
    "    doc_ids = []\n",
    "    contents = []\n",
    "    topics_lst = []\n",
    "    titles = []\n",
    "    for target_file in target_files:\n",
    "        with open(REUTERS_SOURCE_DIR + target_file, 'r', encoding='ISO-8859-1') as f:\n",
    "            src_file = f.read()\n",
    "        soup = BeautifulSoup(src_file, 'html.parser')\n",
    "        for e in soup.find_all('reuters'):\n",
    "            doc_id = e.get('newid')\n",
    "            content = e.find('text')\n",
    "            main_content = (lambda x: x.string if x is not None else '')(content.find('body'))\n",
    "            topics = (lambda x: list(map(lambda y: y.string, x)) if x != [] else x)(e.find('topics').find_all('d'))\n",
    "            title = (lambda x: x.string if x is not None else '')(content.find('title'))\n",
    "\n",
    "            doc_ids.append(doc_id)\n",
    "            contents.append(main_content.strip())\n",
    "            topics_lst.append(topics)\n",
    "            titles.append(title)\n",
    "\n",
    "    # Write corpus\n",
    "    with open(REUTERS_CORPUS_OUTPUT, 'w', newline='') as o:\n",
    "        writer = csv.writer(o)\n",
    "        for doc_id, title, content, topics in zip(doc_ids, contents, topics_lst, titles):\n",
    "            writer.writerow([doc_id, title, content, topics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from text_processing import process\n",
    "from index_configuration import IndexConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "doc_id_list = []\n",
    "with open('../course_corpus_full.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        doc_id = row[0]\n",
    "        title = row[1]\n",
    "        content = row[2]\n",
    "        doc_id_list.append(doc_id)\n",
    "        corpus.append(title + ' '+ content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(s):\n",
    "    return ' '.join(process(s, config=IndexConfiguration(True,True,True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('count', CountVectorizer(preprocessor=preprocessor)),\n",
    "                 ('tfidf', TfidfTransformer(use_idf=True, smooth_idf=True, sublinear_tf=True))]).fit(corpus)\n",
    "\n",
    "# total term frequency over corpus\n",
    "tf_over_corpus = [sum(e) for e in pipe['count'].transform(corpus).transpose().toarray().tolist()]\n",
    "tf_over_corpus_dct = {}\n",
    "\n",
    "terms = pipe['count'].get_feature_names()\n",
    "\n",
    "for i in range(0, len(terms)):\n",
    "    tf_over_corpus_dct[terms[i]] = tf_over_corpus[i]\n",
    "    \n",
    "# pipe['count'].transform(corpus).toarray()\n",
    "\n",
    "tf_idf_matrix = pipe.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def construct_inverted_index(corpus_path: str):\n",
    "    \n",
    "    # Read corpus\n",
    "    corpus = []\n",
    "    doc_id_list = []\n",
    "    with open(corpus_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            doc_id = row[0]\n",
    "            title = row[1]\n",
    "            content = row[2]\n",
    "            doc_id_list.append(doc_id)\n",
    "            corpus.append(title + ' ' + content)\n",
    "            \n",
    "    def preprocessor(s):\n",
    "        return ' '.join(process(s, config=IndexConfiguration(True,True,True)))\n",
    "            \n",
    "    pipe = Pipeline([('count', CountVectorizer(preprocessor=preprocessor)),\n",
    "                 ('tfidf', TfidfTransformer(use_idf=True, smooth_idf=True, sublinear_tf=True))]).fit(corpus)\n",
    "    \n",
    "    terms = pipe['count'].get_feature_names()\n",
    "    \n",
    "    # total term frequency over corpus\n",
    "    tf_over_corpus = [sum(e) for e in pipe['count'].transform(corpus).transpose().toarray().tolist()]\n",
    "    tf_over_corpus_dct = {}\n",
    "    for i in range(0, len(terms)):\n",
    "        tf_over_corpus_dct[terms[i]] = tf_over_corpus[i]\n",
    "\n",
    "    # tf-idf matrix\n",
    "    tfidf_matrix = pipe.transform(corpus)\n",
    "    tfidf_matrix_T_list = tfidf_matrix.transpose().toarray().tolist()\n",
    "    \n",
    "    # inverted index\n",
    "    inverted_index = {}\n",
    "    for i, term in enumerate(terms):\n",
    "        postings = []\n",
    "        tfidf_v_lst = tfidf_matrix_T_list[i]\n",
    "        for tfidf_v, doc_id in zip(tfidf_v_lst, doc_id_list):\n",
    "            if tfidf_v > 0:\n",
    "                postings.append(doc_id)\n",
    "        inverted_index[term] = postings\n",
    "            \n",
    "    return inverted_index, tfidf_matrix, terms, tf_over_corpus_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.07427811622619629\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "tmp = construct_inverted_index('../course_corpus_full.csv')\n",
    "print('Time elapsed: %s' % (time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4106': 1,\n",
       " '4107': 1,\n",
       " 'adversari': 1,\n",
       " 'agent': 1,\n",
       " 'approach': 1,\n",
       " 'artifici': 4,\n",
       " 'aspect': 1,\n",
       " 'basic': 2,\n",
       " 'browser': 1,\n",
       " 'client': 1,\n",
       " 'csi': 2,\n",
       " 'deduct': 1,\n",
       " 'element': 1,\n",
       " 'engin': 1,\n",
       " 'index': 1,\n",
       " 'inform': 7,\n",
       " 'intellig': 4,\n",
       " 'internet': 1,\n",
       " 'introduct': 2,\n",
       " 'knowledg': 2,\n",
       " 'languag': 1,\n",
       " 'learn': 1,\n",
       " 'linguist': 1,\n",
       " 'machin': 1,\n",
       " 'method': 1,\n",
       " 'natur': 1,\n",
       " 'plan': 1,\n",
       " 'principl': 1,\n",
       " 'process': 2,\n",
       " 'program': 1,\n",
       " 'queri': 1,\n",
       " 'reason': 1,\n",
       " 'relat': 1,\n",
       " 'represent': 1,\n",
       " 'retriev': 6,\n",
       " 'root': 1,\n",
       " 'scope': 1,\n",
       " 'search': 4,\n",
       " 'server': 2,\n",
       " 'side': 1,\n",
       " 'the': 1,\n",
       " 'uncertainti': 1,\n",
       " 'unit': 2,\n",
       " 'web': 1,\n",
       " 'wide': 1,\n",
       " 'world': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03476"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.half(np.log10(np.int32(12)/np.int32(13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = csr_matrix([1,2,3])\n",
    "t.data = t.data.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.astype(np.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3 sparse matrix of type '<class 'numpy.float16'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
